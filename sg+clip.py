# -*- coding: utf-8 -*-
"""SG+CLIP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BspA24eiRWcLW4YgWW_-ubZgLziiPmJs
"""

!pip install git+https://github.com/facebookresearch/EGG.git

!pip install transformers

!pip install git+https://github.com/openai/CLIP.git

from transformers import CLIPProcessor, CLIPModel

# Initialize CLIP processor and model
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
print(model.vision_model)

# class PretrainNet(nn.Module):
#     def __init__(self, vision_module):
#         super(PretrainNet, self).__init__()
#         self.vision_module = vision_module
#         self.fc = nn.Linear(512, 10).to(device)

#     def forward(self, x):
#         x = self.vision_module(x)
#         x = self.fc(F.leaky_relu(x))
#         return x

# class_prediction = PretrainNet(CLIPVision()).to(device)
# optimizer = torch.optim.Adam(class_prediction.parameters())

"""MINIST DATASET"""

import torch
import clip
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import torch
import clip
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms

# Load CLIP Model
device = "cuda" if torch.cuda.is_available() else "cpu"
clip_model, preprocess = clip.load("ViT-B/32", device=device)
clip_model = clip_model.float()

#use the visual part of CLIP model
class CLIPVision(nn.Module):
    def __init__(self):
        super(CLIPVision, self).__init__()
        #accesses the visual encoder part of clip model
        self.clip_model = clip_model.visual.to(device)

    def forward(self, x):
        with torch.no_grad():
            #extract features from the image
            x = self.clip_model(x)
        return x

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    preprocess
])


batch_size = 64
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=True, download=True, transform=transform),
    batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=False, transform=transform),
    batch_size=batch_size, shuffle=False)

class Sender(nn.Module):
    def __init__(self, clip_vision_model, vocab_size):
        super(Sender, self).__init__()
        #clip_vision_model: visual part of CLIP model
        self.clip_vision = clip_vision_model
        #vocab_size: encoded message.
        self.encoder = nn.Linear(512, vocab_size)

        #x: number of images
    def forward(self, x):
        #extract image features
        features = self.clip_vision(x)
        #encode these features
        message = self.encoder(features)
        return message

class Receiver(nn.Module):
    def __init__(self, vocab_size, output_size):
        super(Receiver, self).__init__()
        self.decoder = nn.Linear(vocab_size, output_size)

    def forward(self, message):
        #decode the message
        output = self.decoder(message)
        return output

batch_size = 64

train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=True, download=True, transform=transform),
    batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=False, transform=transform),
    batch_size=batch_size, shuffle=False)

#creates an instance of the CLIPVision
clip_vision = CLIPVision().to(device)

vocab_size = 256
output_size = 10
sender = Sender(clip_vision, vocab_size).to(device)
receiver = Receiver(vocab_size, output_size).to(device)

print(sender)
print(receiver)

optimizer = torch.optim.Adam(list(sender.parameters()) + list(receiver.parameters()))
criterion = nn.CrossEntropyLoss()

for epoch in range(4):
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        message = sender(images)
        output = receiver(message)
        loss = criterion(output, labels)
        #computes gradients of the loss with respect to all parameters.
        loss.backward()
        #updates the parameters based on the computed gradients to minimize the loss.
        optimizer.step()

        total_loss += loss.item()

        # Calculate accuracy
        _, predicted = torch.max(output.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    epoch_loss = total_loss / len(train_loader)
    epoch_accuracy = 100 * correct / total
    print(f'Epoch {epoch}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')

"""CIFAR-10 dataset"""

import torch
import clip
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import torch
import clip
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms

# Load CLIP Model
device = "cuda" if torch.cuda.is_available() else "cpu"
clip_model, preprocess = clip.load("ViT-B/32", device=device)
clip_model = clip_model.float()

#use the visual part of CLIP model
class CLIPVision(nn.Module):
    def __init__(self):
        super(CLIPVision, self).__init__()
        #accesses the visual encoder part of clip model
        self.clip_model = clip_model.visual.to(device)

    def forward(self, x):
        with torch.no_grad():
            #extract features from the image
            x = self.clip_model(x)
        return x

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    preprocess
])


batch_size = 64
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=True, download=True, transform=transform),
    batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=False, transform=transform),
    batch_size=batch_size, shuffle=False)

class Sender(nn.Module):
    def __init__(self, clip_vision_model, vocab_size):
        super(Sender, self).__init__()
        #clip_vision_model: visual part of CLIP model
        self.clip_vision = clip_vision_model
        #vocab_size: encoded message.
        self.encoder = nn.Linear(512, vocab_size)

        #x: number of images
    def forward(self, x):
        #extract image features
        features = self.clip_vision(x)
        #encode these features
        message = self.encoder(features)
        return message

class Receiver(nn.Module):
    def __init__(self, vocab_size, output_size):
        super(Receiver, self).__init__()
        self.decoder = nn.Linear(vocab_size, output_size)

    def forward(self, message):
        #decode the message
        output = self.decoder(message)
        return output

batch_size = 64

# train_loader = torch.utils.data.DataLoader(
#     datasets.MNIST('./data', train=True, download=True, transform=transform),
#     batch_size=batch_size, shuffle=True)
# test_loader = torch.utils.data.DataLoader(
#     datasets.MNIST('./data', train=False, transform=transform),
#     batch_size=batch_size, shuffle=False)

train_loader = torch.utils.data.DataLoader(
    datasets.CIFAR10('./data', train=True, download=True, transform=transform),
    batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(
    datasets.CIFAR10('./data', train=False, transform=transform),
    batch_size=batch_size, shuffle=False)

#creates an instance of the CLIPVision
clip_vision = CLIPVision().to(device)

vocab_size = 256
output_size = 10
sender = Sender(clip_vision, vocab_size).to(device)
receiver = Receiver(vocab_size, output_size).to(device)

print(sender)
print(receiver)

optimizer = torch.optim.Adam(list(sender.parameters()) + list(receiver.parameters()))
criterion = nn.CrossEntropyLoss()

for epoch in range(4):
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        message = sender(images)
        output = receiver(message)
        loss = criterion(output, labels)
        #computes gradients of the loss with respect to all parameters.
        loss.backward()
        #updates the parameters based on the computed gradients to minimize the loss.
        optimizer.step()

        total_loss += loss.item()

        # Calculate accuracy
        _, predicted = torch.max(output.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    epoch_loss = total_loss / len(train_loader)
    epoch_accuracy = 100 * correct / total
    print(f'Epoch {epoch}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')

def extract_features(data_loader, model, device):
    features = []
    labels = []
    model.eval()
    with torch.no_grad():
        for images, labels_batch in data_loader:
            images = images.to(device)
            feat = model(images)
            features.append(feat)
            labels.extend(labels_batch.tolist())
    features = torch.cat(features, dim=0)
    return features, torch.tensor(labels)

train_features, train_labels = extract_features(train_loader, CLIPVision(), device)
test_features, test_labels = extract_features(test_loader, CLIPVision(), device)

print(train_features.shape)
print(test_features.shape)
print(train_labels.shape)
print(test_labels.shape)

classifier = nn.Linear(512, 10).to(device)
optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

for epoch in range(10):
    classifier.train()
    optimizer.zero_grad()
    outputs = classifier(train_features)
    loss = criterion(outputs, train_labels.to(device))
    loss.backward()
    optimizer.step()

    print(f'Epoch {epoch}, Loss: {loss.item()}')

def evaluate_features_model(model, features, labels, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        outputs = model(features)
        _, predicted = torch.max(outputs, 1)
        correct = (predicted == labels.to(device)).sum().item()
        total = labels.size(0)
    accuracy = 100 * correct / total
    return accuracy

clip_accuracy = evaluate_features_model(classifier, test_features, test_labels, device)
print("CLIP Features Model Accuracy:", clip_accuracy)

from transformers import CLIPProcessor, CLIPModel

processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
print(model.text_model)

from torchvision.datasets import MNIST
from torch.utils.data import DataLoader, Dataset
import clip
import torch

digit_descriptions = [
    "zero", "one", "two", "three", "four",
    "five", "six", "seven", "eight", "nine"
]

clip_model, _ = clip.load("ViT-B/32", device=device)

text_inputs = torch.cat([clip.tokenize(f"a photo of a {desc}") for desc in digit_descriptions]).to(device)

class CLIPText(nn.Module):
    def __init__(self):
        super(CLIPVision, self).__init__()
        #accesses the visual encoder part of clip model
        self.clip_model = clip_model.text.to(device)

    def forward(self, x):
        with torch.no_grad():
            #extract features from the image
            x = self.clip_model(x)
        return x

class Sender(nn.Module):
    def __init__(self, clip_vision_model, ?vocab_size):
        super(Sender, self).__init__()
        self.clip_vision = clip_vision_model
        self.encoder = nn.Linear(?, vocab_size)

    def forward(self, x):
        features = self.clip_vision(x)
        message = self.encoder(features)
        return message

class Receiver(nn.Module):
    def __init__(self, clip_model, ?vocab_size, ?num_classes):
        super(Receiver, self).__init__()
        self.decoder = nn.Linear(vocab_size, num_classes)
        self.clip_model = clip_model

    def forward(self, message, text_tokens):
        text_features = self.clip_model.encode_text(text_tokens).float()
        output = self.decoder(message)
        return output
        # return (output @ text_features.T)

train_dataset = TextualMNIST('./data', train=True, transform=transform)
test_dataset = TextualMNIST('./data', train=False, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

vocab_size = ?
clip_vision = CLIPVision().to(device).float()
receiver = Receiver(clip_model, vocab_size, len(digit_descriptions)).to(device).float()

optimizer = torch.optim.Adam(list(sender.parameters()) + list(receiver.parameters()), lr=0.001)
criterion = nn.CrossEntropyLoss()

for epoch in range(4):
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        message = sender(images)
        output = receiver(message)
        loss = criterion(output, labels)
        #computes gradients of the loss with respect to all parameters.
        loss.backward()
        #updates the parameters based on the computed gradients to minimize the loss.
        optimizer.step()

        total_loss += loss.item()

        # Calculate accuracy
        _, predicted = torch.max(output.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    epoch_loss = total_loss / len(train_loader)
    epoch_accuracy = 100 * correct / total
    print(f'Epoch {epoch}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')

def evaluate_model(model, data_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in data_loader:
            images, labels = images.to(device), labels.to(device)
            output = model(images)
            _, predicted = torch.max(output.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    return accuracy

# Evaluate both models
accuracy_signaling = evaluate_model(receiver, test_loader, device)

print("Signaling Game Accuracy:", accuracy_signaling)

import torch

def evaluate_clip_model(clip_model, data_loader, device, text_prompts):
    clip_model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in data_loader:
            images = images.to(device)

            # Prepare text inputs for CLIP
            text_inputs = torch.cat([clip.tokenize(text_prompts[label.item()]) for label in labels]).to(device)

            # Forward pass through CLIP
            logits_per_image, _ = clip_model(images, text_inputs)
            predictions = logits_per_image.softmax(dim=-1).argmax(dim=-1)

            total += labels.size(0)
            correct += (predictions == labels.to(device)).sum().item()

    accuracy = 100 * correct / total
    return accuracy

# Define text prompts corresponding to classes
text_prompts = [
    "a photo of a zero", "a photo of a one", "a photo of a two", "a photo of a three",
    "a photo of a four", "a photo of a five", "a photo of a six", "a photo of a seven",
    "a photo of an eight", "a photo of a nine"
]

# Evaluate CLIP model
accuracy_clip = evaluate_clip_model(clip_model, test_loader, device, text_prompts)
print("CLIP Model Accuracy:", accuracy_clip)

import torch
import clip
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import torch
import clip
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms

# Load CLIP Model
device = "cuda" if torch.cuda.is_available() else "cpu"
clip_model, preprocess = clip.load("ViT-B/32", device=device)
clip_model = clip_model.float()

class CLIPVision(nn.Module):
    def __init__(self):
        super(CLIPVision, self).__init__()
        self.clip_model = clip_model.visual.to(device)

    def forward(self, x):
        with torch.no_grad():
            x = self.clip_model(x)
        return x

class PretrainNet(nn.Module):
    def __init__(self, vision_module):
        super(PretrainNet, self).__init__()
        self.vision_module = vision_module
        self.fc = nn.Linear(512, 10).to(device)

    def forward(self, x):
        x = self.vision_module(x)
        x = self.fc(F.leaky_relu(x))
        return x

# Initialize model
class_prediction = PretrainNet(CLIPVision()).to(device)  # Move entire model to device
optimizer = torch.optim.Adam(class_prediction.parameters())

# Define transformations and data loaders
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images for CLIP
    preprocess  # Apply CLIP's preprocessing which includes converting to tensor
])

batch_size = 64
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=True, download=True, transform=transform),
    batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=False, transform=transform),
    batch_size=batch_size, shuffle=False)

class Sender(nn.Module):
    def __init__(self, clip_vision_model, hidden_size):
        super(Sender, self).__init__()
        self.clip_vision = clip_vision_model
        self.encoder = nn.Linear(512, hidden_size)

    def forward(self, x):
        features = self.clip_vision(x)
        message = self.encoder(features)
        return message

class Receiver(nn.Module):
    def __init__(self, hidden_size, output_size):
        super(Receiver, self).__init__()
        self.decoder = nn.Linear(hidden_size, output_size)

    def forward(self, message):
        output = self.decoder(message)
        return output

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    preprocess
])

batch_size = 64

train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=True, download=True, transform=transform),
    batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=False, transform=transform),
    batch_size=batch_size, shuffle=False)

device = "cuda" if torch.cuda.is_available() else "cpu"
clip_model, preprocess = clip.load("ViT-B/32", device=device)
clip_model = clip_model.float()
clip_vision = CLIPVision().to(device)


hidden_size = 256
output_size = 10
sender = Sender(clip_vision, hidden_size).to(device)
receiver = Receiver(hidden_size, output_size).to(device)


optimizer = torch.optim.Adam(list(sender.parameters()) + list(receiver.parameters()))
criterion = nn.CrossEntropyLoss()

game = core.SymbolGameGS(sender, receiver, loss)

print(game)

optimizer = torch.optim.Adam(game.parameters())

trainer = core.Trainer(
    game=game, optimizer=optimizer, train_data=train_loader,
    validation_data=test_loader, callbacks=[core.TemperatureUpdater(agent=sender, decay=0.9, minimum=0.1)]
)

n_epochs = 15
trainer.train(n_epochs)

# for epoch in range(4):
#     for images, labels in train_loader:
#         images, labels = images.to(device), labels.to(device)

#         optimizer.zero_grad()
#         message = sender(images)
#         output = receiver(message)
#         loss = criterion(output, labels)
#         loss.backward()
#         optimizer.step()

#     print(f'Epoch {epoch}, Loss: {loss.item()}')

print("Signaling Game Accuracy:", accuracy_signaling)

import torch
import clip
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np

# Load CLIP model
device = "cuda" if torch.cuda.is_available() else "cpu"
clip_model, preprocess = clip.load("ViT-B/32", device=device)

# Define transformation and DataLoader for MNIST
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images for CLIP
    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to three-channel
    transforms.ToTensor(),
    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))  # Normalize for three-channel images
])

# Load MNIST dataset
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=True, download=True, transform=transform),
    batch_size=9, shuffle=True)

# Fetch a single batch of images
images, labels = next(iter(train_loader))

# Process images through CLIP
images = images.to(device)
with torch.no_grad():
    image_features = clip_model.encode_image(images)

# Display the images and features (optional)
fig, axes = plt.subplots(3, 3, figsize=(10, 10))
for i, ax in enumerate(axes.flat):
    img = images[i].cpu().numpy()
    img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)
    img = np.clip(img, 0, 1)  # Ensure the image values are valid
    ax.imshow(img, cmap='gray')
    ax.set_title(f'Label: {labels[i]}')
    ax.axis('off')

plt.show()

def evaluate_model(model, data_loader, criterion, device):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in data_loader:
            images, labels = images.to(device), labels.to(device)
            # Reshape appropriately considering the network's architecture
            images = images.view(images.shape[0], -1)  # Flatten or apply appropriate conversion
            output = model(images)
            loss = criterion(output, labels)
            total_loss += loss.item()
            _, predicted = torch.max(output.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = total_loss / len(data_loader)
    accuracy = correct / total * 100
    return avg_loss, accuracy

# Usage
avg_loss, accuracy = evaluate_model(receiver, test_loader, criterion, device)
print(f'Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')

def reward_function(outputs, labels):
    _, predicted = outputs.max(1)
    rewards = (predicted == labels).float()
    return rewards


for epoch in range(10):
    total_reward = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        message = sender(images)
        output = receiver(message)
        loss = criterion(output, labels)
        rewards = reward_function(output, labels)
        loss = loss * (1 - rewards)
        loss.backward()
        optimizer.step()

        total_reward += rewards.sum().item()

    average_reward = total_reward / len(train_loader.dataset)
    print(f'Epoch {epoch}, Loss: {loss.item()}, Avg Reward: {average_reward}')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %load_ext autoreload
# %autoreload 2

import torch
from torchvision import datasets, transforms
import torch
import torch.nn as nn
import egg.core as core

from torchvision import datasets, transforms
from torch import nn
from torch.nn import functional as F

import matplotlib.pyplot as plt
import random
import numpy as np

from pylab import rcParams
rcParams['figure.figsize'] = 5, 10


opts = core.init(params=['--random_seed=7',
                         '--lr=1e-3',
                         '--batch_size=32',
                         '--optimizer=adam'])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# class Vision(nn.Module):
#     def __init__(self):
#         super(Vision, self).__init__()
#         # Update input channels to 3 for RGB images
#         self.conv1 = nn.Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))
#         self.conv2 = nn.Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
#         # Calculate the resulting output size after convolutions
#         self.fc1 = nn.Linear(self.calculate_flattened_features(32, 32), 500)

#     def forward(self, x):
#         x = F.relu(self.conv1(x))
#         x = F.relu(self.conv2(x))
#         x = x.view(x.size(0), -1)
#         x = self.fc1(x)
#         return x

#     def calculate_flattened_features(self, height, width):
#         # Simulate the convolutions to determine the output size
#         size = torch.zeros((1, 3, height, width))
#         size = self.conv1(size)
#         size = self.conv2(size)
#         return int(torch.numel(size) / size.shape[0])

class Vision(nn.Module):
    def __init__(self):
        super(Vision, self).__init__()
        self.conv1 = nn.Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))
        self.bn1 = nn.BatchNorm2d(20)
        self.conv2 = nn.Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
        self.bn2 = nn.BatchNorm2d(50)
        self.fc1 = nn.Linear(50 * 24 * 24, 500)  # Adjusted based on new output size after conv

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        return x


class PretrainNet(nn.Module):
    def __init__(self, vision_module):
        super(PretrainNet, self).__init__()
        self.vision_module = vision_module
        self.fc = nn.Linear(500, 10)  # Output layer for 10 classes

    def forward(self, x):
        x = self.vision_module(x)
        x = self.fc(F.leaky_relu(x))
        return x


# kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}
# transform = transforms.ToTensor()

# batch_size = opts.batch_size # set via the CL arguments above
# train_loader = torch.utils.data.DataLoader(
#         datasets.MNIST('./data', train=True, download=True,
#            transform=transform),
#            batch_size=batch_size, shuffle=True, **kwargs)
# test_loader = torch.utils.data.DataLoader(
#         datasets.MNIST('./data', train=False, transform=transform),
#            batch_size=batch_size, shuffle=False, **kwargs)



# Check if CUDA is available and set DataLoader parameters
kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Set the batch size, typically set via command line arguments
batch_size = opts.batch_size

train_loader = torch.utils.data.DataLoader(
    datasets.CIFAR10('./data', train=True, download=True, transform=transform),
    batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.CIFAR10('./data', train=False, transform=transform),
    batch_size=batch_size, shuffle=False, drop_last=True, **kwargs)

vision = Vision()
class_prediction = PretrainNet(vision) #  note that we pass vision - which we want to pretrain
print(class_prediction)
optimizer = core.build_optimizer(class_prediction.parameters()) #  uses command-line parameters we passed to core.init
class_prediction = class_prediction.to(device)

for epoch in range(20):
    mean_loss, n_batches = 0, 0
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = class_prediction(data)
        loss = F.cross_entropy(output, target)
        loss.backward()
        optimizer.step()

        mean_loss += loss.mean().item()
        n_batches += 1

    print(f'Train Epoch: {epoch}, mean loss: {mean_loss / n_batches}')

def visualize_model_predictions(model, data_loader, device, num_images=5):
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(data_loader):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images, 2, images_so_far)
                ax.axis('off')
                ax.set_title(f'predicted: {preds[j]} / true: {labels[j]}')
                img = inputs.cpu().data[j].numpy().transpose((1, 2, 0))
                img = np.clip(img, 0, 1)
                plt.imshow(img)

                if images_so_far == num_images:
                    model.train(mode=True)
                    return plt

    model.train(mode=True)

plt_visualization = visualize_model_predictions(class_prediction, test_loader, device)

plt_visualization.show()

print(vision)

print(vision)

import os
os.environ['CUDA_LAUNCH_BLOCKING'] = "1"

# class Sender(nn.Module):
#     def __init__(self, vision, output_size):
#         super(Sender, self).__init__()
#         self.fc = nn.Linear(500, output_size)
#         self.vision = vision

#     def forward(self, x, aux_input=None):
#         x = self.vision(x)  # Ensure vision is called without torch.no_grad()
#         x = self.fc(x)
#         return x

class Sender(nn.Module):
    def __init__(self, vision, output_size):
        super(Sender, self).__init__()
        self.fc = nn.Linear(500, output_size)
        self.vision = vision

    def forward(self, x, aux_input=None):
        x = self.vision(x)
        x = self.fc(x)
        return x

# class Receiver(nn.Module):
#     def __init__(self, input_size):
#         super(Receiver, self).__init__()
#         # Output 3*32*32 = 3072 for RGB images of size 32x32
#         self.fc = nn.Linear(input_size, 3*32*32)

#     def forward(self, channel_input, receiver_input=None, aux_input=None):
#         x = self.fc(channel_input)
#         return torch.sigmoid(x)  # Outputs are between 0 and 1

class Receiver(nn.Module):
    def __init__(self, input_size):
        super(Receiver, self).__init__()
        self.fc1 = nn.Linear(input_size, 1024)
        self.dropout = nn.Dropout(p=0.5)
        self.fc2 = nn.Linear(1024, 3*32*32)

    def forward(self, channel_input, receiver_input=None, aux_input=None):
        x = F.relu(self.fc1(channel_input))
        x = self.dropout(x)
        x = self.fc2(x)
        return torch.sigmoid(x).view(-1, 3, 32, 32)

# sender = Sender(vision, output_size=625)
# receiver = Receiver(input_size=625)

def loss(sender_input, _message, _receiver_input, receiver_output, _labels, _aux_input=None):
    target = sender_input / 255.0
    target = torch.clamp(target, 0, 1)

    receiver_output = receiver_output.view(target.size())

    return F.binary_cross_entropy(receiver_output, target, reduction='sum'), {}

# def loss_function(output, target):
#     # Assume output and target are both [batch_size, 3, 32, 32]
#     return F.mse_loss(output, target)  # Or bi

vocab_size = 32

# sender = Sender(vision, vocab_size)
# sender = core.GumbelSoftmaxWrapper(sender, temperature=1.0) # wrapping into a GS interface, requires GS temperature
# receiver = Receiver(input_size=625)
# receiver = core.SymbolReceiverWrapper(receiver, vocab_size, agent_input_size=625)

# game = core.SymbolGameGS(sender, receiver, loss)

sender_vision = Vision()
sender = Sender(vision=sender_vision, output_size=10)
sender = core.GumbelSoftmaxWrapper(sender, temperature=1.0)

receiver = Receiver(input_size=400)
receiver = core.SymbolReceiverWrapper(receiver, vocab_size=10, agent_input_size=400)

game = core.SymbolGameGS(sender, receiver, loss)

print(game)

optimizer = torch.optim.Adam(game.parameters())

trainer = core.Trainer(
    game=game, optimizer=optimizer, train_data=train_loader,
    validation_data=test_loader, callbacks=[core.TemperatureUpdater(agent=sender, decay=0.9, minimum=0.1)]
)

n_epochs = 15
trainer.train(n_epochs)

import matplotlib.pyplot as plt
import torch

def plot_image_from_tensor(tensor):
    tensor = tensor.detach()
    tensor = tensor.cpu().numpy()
    plt.imshow(np.transpose(tensor, (1, 2, 0)))
    plt.axis('off')
    plt.show()

game.eval()
test_data = next(iter(test_loader))
input_images, _ = test_data

input_images = input_images.to(next(sender.parameters()).device)
sender_output = sender(input_images)
receiver_output = receiver(sender_output)

plot_image_from_tensor(receiver_output[0])
print(receiver_output.min().item(), receiver_output.max().item())

game.eval()

for z in range(vocab_size):
    t = torch.zeros(1, 10).to(device)
    t[0, z % 10] = 1

    with torch.no_grad():
        sample = game.receiver(t).float().cpu()

    sample = sample.view(32, 32, 3)
    plt.title(f"Input: symbol {z}")
    plt.imshow(sample)
    plt.show()

import torch
from PIL import Image
from torchvision import transforms

test_inputs = []

transform = transforms.Compose([
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])


image_paths = [
    '/content/Cute_dog.jpg',
]

for image_path in image_paths:
    img = Image.open(image_path).convert('L')
    img_transformed = transform(img)
    test_inputs.append(img_transformed.unsqueeze(0))

test_inputs = torch.cat(test_inputs)

test_inputs = []
for z in range(10):
    index = (test_loader.dataset.targets[:100] == z).nonzero()[0, 0]
    img, _ = test_loader.dataset[index]
    test_inputs.append(img.unsqueeze(0))
test_inputs = torch.cat(test_inputs)

test_dataset = [[test_inputs, None]]

def plot(game, test_dataset, is_gs, variable_length):
    interaction = \
            core.dump_interactions(game, test_dataset, is_gs, variable_length)

    for z in range(10):
        src = interaction.sender_input[z].squeeze(0)
        dst = interaction.receiver_output[z].view(28, 28)
        image = torch.cat([src, dst], dim=1).cpu().numpy()

        plt.title(f"Input: digit {z}, channel message {interaction.message[z]}")
        plt.imshow(image, cmap='gray')
        plt.show()

plot(game, test_dataset, is_gs=True, variable_length=False)

sender = Sender(vision, output_size=vocab_size)
sender = core.ReinforceWrapper(sender)

receiver = Receiver(input_size=400)
receiver = core.SymbolReceiverWrapper(receiver, vocab_size, agent_input_size=400)
receiver = core.ReinforceDeterministicWrapper(receiver)

game = core.SymbolGameReinforce(sender, receiver, loss, sender_entropy_coeff=0.05, receiver_entropy_coeff=0.0)
optimizer = torch.optim.Adam(game.parameters(), lr=1e-2)

trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train_loader,
                           validation_data=test_loader)

n_epochs = 15
trainer.train(n_epochs)

import torch
import torch.nn as nn
import egg.core as core

from torchvision import datasets, transforms
from torch import nn
from torch.nn import functional as F

import matplotlib.pyplot as plt
import random
import numpy as np

from pylab import rcParams
rcParams['figure.figsize'] = 5, 10


opts = core.init(params=['--random_seed=7',
                         '--lr=1e-3',
                         '--batch_size=32',
                         '--optimizer=adam'])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class Vision(nn.Module):
    def __init__(self):
        super(Vision, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        return x

class PretrainNet(nn.Module):
    def __init__(self, vision_module):
        super(PretrainNet, self).__init__()
        self.vision_module = vision_module
        self.fc = nn.Linear(500, 10)

    def forward(self, x):
        x = self.vision_module(x)
        x = self.fc(F.leaky_relu(x))
        return x

kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}
transform = transforms.ToTensor()

batch_size = opts.batch_size
train_loader = torch.utils.data.DataLoader(
        datasets.MNIST('./data', train=True, download=True,
           transform=transform),
           batch_size=batch_size, shuffle=True, **kwargs)
test_loader = torch.utils.data.DataLoader(
        datasets.MNIST('./data', train=False, transform=transform),
           batch_size=batch_size, shuffle=False, **kwargs)

vision = Vision()
class_prediction = PretrainNet(vision)
optimizer = core.build_optimizer(class_prediction.parameters())
class_prediction = class_prediction.to(device)

for epoch in range(10):
    mean_loss, n_batches = 0, 0
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = class_prediction(data)
        loss = F.cross_entropy(output, target)
        loss.backward()
        optimizer.step()

        mean_loss += loss.mean().item()
        n_batches += 1

    print(f'Train Epoch: {epoch}, mean loss: {mean_loss / n_batches}')

class Sender(nn.Module):
    def __init__(self, vision, output_size):
        super(Sender, self).__init__()
        self.fc = nn.Linear(500, output_size)
        self.vision = vision

    def forward(self, x, aux_input=None):
        with torch.no_grad():
            x = self.vision(x)
        x = self.fc(x)
        return x


class Receiver(nn.Module):
    def __init__(self, input_size):
        super(Receiver, self).__init__()
        self.fc = nn.Linear(input_size, 784)

    def forward(self, channel_input, receiver_input=None, aux_input=None):
        x = self.fc(channel_input)
        return torch.sigmoid(x)

sender = Sender(vision, output_size=400)
receiver = Receiver(input_size=400)

def loss(sender_input, _message, _receiver_input, receiver_output, _labels, _aux_input=None):
    loss = F.binary_cross_entropy(receiver_output, sender_input.view(-1, 784), reduction='none').mean(dim=1)
    return loss, {}

vocab_size = 10

sender = Sender(vision, vocab_size)
sender = core.GumbelSoftmaxWrapper(sender, temperature=1.0)
receiver = Receiver(input_size=400)
receiver = core.SymbolReceiverWrapper(receiver, vocab_size, agent_input_size=400)

game = core.SymbolGameGS(sender, receiver, loss)
optimizer = torch.optim.Adam(game.parameters())

print(game)
print(vision)

trainer = core.Trainer(
    game=game, optimizer=optimizer, train_data=train_loader,
    validation_data=test_loader, callbacks=[core.TemperatureUpdater(agent=sender, decay=0.9, minimum=0.1)]
)

n_epochs = 15
trainer.train(n_epochs)

